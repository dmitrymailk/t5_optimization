{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/ai-forever/sage.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd sage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install .\n",
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load functionality\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from sage.spelling_correction import T5ModelForSpellingCorruption, RuM2M100ModelForSpellingCorrection, AvailableCorrectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick tour [English]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load corrector\n",
    "\n",
    "corrector = T5ModelForSpellingCorruption.from_pretrained(AvailableCorrectors.ent5_large.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place model on your favorite device\n",
    "\n",
    "corrector.model.to(torch.device(\"cuda:0\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate correct texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply, corrector's API have two methods that allow \n",
    "you to generate correct text. \n",
    "\n",
    "First, `correct()` method: use it when you have single sample. \n",
    "You can also provide additional `prefix` argument if needed, \n",
    "and `**generation_params` of your choice.\n",
    "\n",
    "Apparent counterpart is `batch_correct` method.\n",
    "As a name suggests, most useful when you've batch of texts to correct.\n",
    "You may also provide `batch_size` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagine you have bunch of texts with broken spelling.\n",
    "\n",
    "samples = [\n",
    "    \"So I think we would not be live if our ancestors did not develop siences and tecnologies.\",\n",
    "    \"There are very successful politicians that have never tried somthing new.\",\n",
    "    \"second , birds navigate by landmarks like river , coastlines , and moutains.\",\n",
    "    \"Because of this , I prefer studying concepts and ideas more thad learnig facts.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's been trained with \"grammar: \" prefix. \n",
    "# Don't forget to past `prefix` when calling corresponding methods.\n",
    "\n",
    "result = corrector.correct(samples[0], prefix=\"grammar: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So I think we would not be alive if our ancestors did not develop sciences and technologies.\n"
     ]
    }
   ],
   "source": [
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_result = corrector.batch_correct(samples, batch_size=1, prefix=\"grammar: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['So I think we would not be alive if our ancestors did not develop sciences and technologies.']\n",
      "['There are very successful politicians that have never tried something new.']\n",
      "['second, birds navigate by landmarks like rivers, coastlines, and mountains.']\n",
      "['Because of this, I prefer studying concepts and ideas more than learning facts.']\n"
     ]
    }
   ],
   "source": [
    "print(*batch_result, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with bigger `batch_size`\n",
    "\n",
    "batch_result = corrector.batch_correct(samples, batch_size=4, prefix=\"grammar: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So I think we would not be alive if our ancestors did not develop sciences and technologies.\n",
      "There are very successful politicians that have never tried something new.\n",
      "second, birds navigate by landmarks like rivers, coastlines, and mountains.\n",
      "Because of this, I prefer studying concepts and ideas more than learning facts.\n"
     ]
    }
   ],
   "source": [
    "print(*batch_result[0], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different `**generation_params`\n",
    "\n",
    "batch_result = corrector.batch_correct(\n",
    "    samples, batch_size=1, prefix=\"grammar: \", num_return_sequences=2, do_sample=True, top_k=50, top_p=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So I think we would not be alive if our ancestors did not develop sciences and technologies.\n",
      "So I think we would not be alive if our ancestors did not develop sciences and technologies.\n",
      "\n",
      "There are very successful politicians that have never tried something new.\n",
      "There are very successful politicians that have never tried something new.\n",
      "\n",
      "second, birds navigate by landmarks like rivers, coastlines, and mountains.\n",
      "second, birds navigate by landmarks like rivers, coastlines, and mountains.\n",
      "\n",
      "Because of this, I prefer studying concepts and ideas more than learning facts.\n",
      "Because of this, I prefer studying concepts and ideas more than learning facts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for elem in batch_result:\n",
    "    print(*elem, sep=\"\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation on JFLEG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call the evaluation on any dataset that is available \n",
    "either on HF hub or localy.\n",
    "\n",
    "Remember, it should be properly formatted. \n",
    "Two text files: `sources.txt` and `corrections.txt` in one folder. If you prefer\n",
    "single file, you may want to use `data.csv` with two columns `source` and `correction`. \n",
    "Or just write down the correct name of dataset on HF hub. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to stay inside sage directory or change path to validation data\n",
    "\n",
    "metrics = corrector.evaluate(\n",
    "    os.path.join(os.getcwd(), \"data\", \"example_data\", \"jfleg\"), batch_size=32, prefix=\"grammar: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': 83.43, 'Recall': 84.25, 'F1': 83.84}\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick tour [Russian]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m2m100_1B: ai-forever/RuM2M100-1.2B\n",
      "m2m100_418M: ai-forever/RuM2M100-418M\n",
      "fred_large: ai-forever/FRED-T5-large-spell\n",
      "ent5_large: ai-forever/T5-large-spell\n"
     ]
    }
   ],
   "source": [
    "# For Russian we have wider range of available models.\n",
    "# P.S. ent5_large model corresponds to the English language, of course)\n",
    "\n",
    "print(*[\"{}: {}\".format(item.name, item.value) for item in AvailableCorrectors], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load corrector\n",
    "\n",
    "# NOTE: all three models may exceed the amount of RAM available in free version of Colab. \n",
    "# If the case, comment out one or two models and make sure to comment corresponding outputs and samples.\n",
    "\n",
    "m2m_1b_corrector = RuM2M100ModelForSpellingCorrection.from_pretrained(AvailableCorrectors.m2m100_1B.value)\n",
    "m2m_418m_corrector = RuM2M100ModelForSpellingCorrection.from_pretrained(AvailableCorrectors.m2m100_418M.value)\n",
    "fred_corrector = T5ModelForSpellingCorruption.from_pretrained(AvailableCorrectors.fred_large.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make up some spoiled sentences\n",
    "\n",
    "samples = [\n",
    "    \"прийдя в МГТУ я был удивлен никого необноружив там…\",\n",
    "    \"Нащщот Чавеса разве что не соглашусь.\",\n",
    "    \"Мошный лазер - в нерабочем состоянии - 350 кредиток.\",\n",
    "    \"Ощушаю себя с ними монголойдом, я никогда так много не молчала как молчю тут, и не потому, что языковый баръер или еще что-то, просто коментариев нет\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1b = m2m_1b_corrector.correct(samples[0])\n",
    "result_418m = m2m_418m_corrector.correct(samples[0])\n",
    "result_fred = fred_corrector.correct(samples[0], prefix=\"Исправь: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m2m1b\n",
      "прийдя в МГТУ я был удивлен никого не обнаружив там...\n",
      "\n",
      "m2m418m\n",
      "Прийдя в МГТУ, я был удивлен, никого не обнаружив там...\n",
      "\n",
      "fred\n",
      "прийдя в МГТУ я был удивлен никого не обнаружив там.. «при\n"
     ]
    }
   ],
   "source": [
    "print(\"m2m1b\")\n",
    "print(result_1b[0])\n",
    "print()\n",
    "\n",
    "print(\"m2m418m\")\n",
    "print(result_418m[0])\n",
    "print()\n",
    "\n",
    "print(\"fred\")\n",
    "print(result_fred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1b = m2m_1b_corrector.batch_correct(samples, batch_size=1)\n",
    "result_418m = m2m_418m_corrector.batch_correct(samples, batch_size=1)\n",
    "result_fred = fred_corrector.batch_correct(samples, prefix=\"Исправь: \", batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m2m1b\n",
      "['прийдя в МГТУ я был удивлен никого не обнаружив там...']\n",
      "['Насчет Чавеса разве что не соглашусь.']\n",
      "['Мощный лазер - в нерабочем состоянии - 350 кредиток.']\n",
      "['Ощущаю себя с ними монголойдом, я никогда так много не молчала как молчу тут, и не потому, что языковый барьер или еще что-то, просто комментариев нет']\n",
      "\n",
      "m2m418m\n",
      "['Прийдя в МГТУ, я был удивлен, никого не обнаружив там...']\n",
      "['Нащ от Чавеса. Разве что не соглашусь...']\n",
      "['Мощный лазер - в нерабочем состоянии - 350 кредиток.']\n",
      "['Ощушаю себя с ними монголойдом. Я никогда так много не молчала, как молчаю тут. И не потому, что языковый баръер или еще что-то, просто комментариев нет.']\n",
      "\n",
      "fred\n",
      "['прийдя в МГТУ я был удивлен никого не обнаружив там.. «при']\n",
      "['На счет Чавеса разве что не соглашусь. На счет']\n",
      "['Мощный лазер - в нерабочем состоянии - 350 кредиток']\n",
      "['Ощущаю себя с ними монголойдом, я никогда так много не молчала как молчу тут, и не потому, что языковый барьер или еще что-то, просто коментариев нет, просто ком']\n"
     ]
    }
   ],
   "source": [
    "print(\"m2m1b\")\n",
    "print(*result_1b, sep=\"\\n\")\n",
    "print()\n",
    "\n",
    "print(\"m2m418m\")\n",
    "print(*result_418m, sep=\"\\n\")\n",
    "print()\n",
    "\n",
    "print(\"fred\")\n",
    "print(*result_fred, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1b = m2m_1b_corrector.batch_correct(\n",
    "    samples, batch_size=1, num_return_sequences=2, do_sample=True, top_k=50, top_p=0.95)\n",
    "result_418m = m2m_418m_corrector.batch_correct(\n",
    "    samples, batch_size=1, num_return_sequences=2, do_sample=True, top_k=50, top_p=0.95)\n",
    "result_fred = fred_corrector.batch_correct(\n",
    "    samples, batch_size=1, prefix=\"Исправь: \", num_return_sequences=2, do_sample=True, top_k=50, top_p=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = \"\\n------------------------------------------------------------------------------------------------------------\\n\"\n",
    "result_1b = [elem[0] + \"\\n\" + elem[1] for elem in result_1b] \n",
    "result_418m = [elem[0] + \"\\n\" + elem[1] for elem in result_418m] \n",
    "result_fred = [elem[0] + \"\\n\" + elem[1] for elem in result_fred] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m2m1b\n",
      "прийдя в МГТУ я был удивлен никого не обнаружив там...\n",
      "прийдя в МГТУ я был удивлен никого не обнаружив там...\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Насчет Чавеса разве что не соглашусь.\n",
      "Насчет Чавеса разве что не соглашусь.\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Мощный лазер - в нерабочем состоянии - 350 кредиток.\n",
      "Мощный лазер - в нерабочем состоянии - 350 кредиток.\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Ощущаю себя с ними монголойдом, я никогда так много не молчала как молчу тут, и не потому, что языковый барьер или еще что-то, просто комментариев нет\n",
      "Ощущаю себя с ними монголойдом, я никогда так много не молчала как молчу тут, и не потому, что языковый барьер или еще что-то, просто комментариев нет\n",
      "\n",
      "m2m418m\n",
      "Прийдя в МГТУ, я был удивлен, никого не обнаружив там...\n",
      "Прийдя в МГТУ, я был удивлен, никого не обнаружив там...\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Нащ от Чавеса. Разве что не соглашусь...\n",
      "На щот Чавеса разве что не соглашусь.\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Мощный лазер - в нерабочем состоянии - 350 кредиток.\n",
      "Мощный лазер - в нерабочем состоянии - 350 кредиток.\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Ощушаю себя с ними монголойдом. Я никогда так много не молчала, как молчаю тут. И не потому, что языковый баръер или еще что-то, просто комментариев нет.\n",
      "Ощушаю себя с ними монголойдом. Я никогда так много не молчала, как молчаю тут. И не потому, что языковый баръер или еще что-то, просто комментариев нет.\n",
      "\n",
      "fred\n",
      "прийдя в МГТУ я был удивлен никого необнаружив там.. в\n",
      "прийдя в МГТУ я был удивлен никого необнаружив там“...\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Нащот Чавеса разве что не соглашусь. На\n",
      "На счет Чавеса разве что не соглашусь. Насчет Ча\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Мощный лазер - в нерабочем состоянии - 350 кредиток\n",
      "Мощный лазер - в нерабочем состоянии - 350 кредиток\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Ощущаю себя с ними монголойдом, я никогда так много не молчала как молчу тут, и не потому, что языковый барьер или еще что-то, просто комментариев нет, просто коментариев\n",
      "Ощущаю себя с ними монголойдом, я никогда так много не молчала как молчу тут, и не потому, что языковый барьер или еще что-то, просто коментариев нет, просто ком\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"m2m1b\")\n",
    "print(*result_1b, sep=sep)\n",
    "print()\n",
    "\n",
    "print(\"m2m418m\")\n",
    "print(*result_418m, sep=sep)\n",
    "print()\n",
    "\n",
    "print(\"fred\")\n",
    "print(*result_fred, sep=sep)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load available datasets\n",
    "\n",
    "from sage.utils import DatasetsAvailable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultidomainGold: Multidomain gold dataset. For more see `ai-forever/spellcheck_benchmark`.\n",
      "RUSpellRU: Social media texts and blogs. For more see `ai-forever/spellcheck_benchmark`.\n",
      "MedSpellchecker: Medical anamnesis. For more see `ai-forever/spellcheck_benchmark`.\n",
      "GitHubTypoCorpusRu: Github commits. For more see `ai-forever/spellcheck_benchmark`.\n"
     ]
    }
   ],
   "source": [
    "# Available datasets at HF hub\n",
    "\n",
    "print(*[\"{}: {}\".format(item.name, item.value) for item in DatasetsAvailable], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2M100-1.2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place model on device\n",
    "\n",
    "m2m_1b_corrector.model.to(torch.device(\"cuda:0\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = m2m_1b_corrector.evaluate(\"RUSpellRU\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m2m1b RUSpellRU:\n",
      "{'Precision': 59.44, 'Recall': 43.32, 'F1': 50.12}\n"
     ]
    }
   ],
   "source": [
    "print(\"m2m1b RUSpellRU:\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2M100-418M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place model on device\n",
    "\n",
    "m2m_418m_corrector.model.to(torch.device(\"cuda:0\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = m2m_418m_corrector.evaluate(\"MultidomainGold\", batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m2m418m MultidomainGold:\n",
      "{'Precision': 32.82, 'Recall': 57.69, 'F1': 41.84}\n"
     ]
    }
   ],
   "source": [
    "print(\"m2m418m MultidomainGold:\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FredT5-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place model on device\n",
    "\n",
    "fred_corrector.model.to(torch.device(\"cuda:0\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = fred_corrector.evaluate(\"GitHubTypoCorpusRu\", prefix=\"Исправь: \", batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fred GitHubTypoCorpusRu:\n",
      "{'Precision': 52.73, 'Recall': 41.75, 'F1': 46.6}\n"
     ]
    }
   ],
   "source": [
    "print(\"fred GitHubTypoCorpusRu:\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
