{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sage.spelling_correction import (\n",
    "    RuM2M100ModelForSpellingCorrection,\n",
    "    AvailableCorrectors,\n",
    ")\n",
    "from datetime import datetime\n",
    "\n",
    "\"\"\"API to T5-based models for spelling correction.\n",
    "\n",
    "To load a model:\n",
    "\n",
    "    from corrector import AvailableCorrectors\n",
    "\n",
    "    model = T5ModelForSpellingCorruption.from_pretrained(AvailableCorrectors.fred_large.value)\n",
    "    ...\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import List, Optional, Union, Any\n",
    "from tqdm import tqdm\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "from sage.spelling_correction.corrector import Corrector\n",
    "\n",
    "\n",
    "class T5ModelForSpellingCorruption(Corrector):\n",
    "    \"\"\"T5-based models.\"\"\"\n",
    "\n",
    "    def __init__(self, model_name_or_path: Union[str, os.PathLike]):\n",
    "        self.model_name_or_path = model_name_or_path\n",
    "        self.max_model_length = 512\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_name_or_path: Union[str, os.PathLike]):\n",
    "        engine = cls(model_name_or_path)\n",
    "        engine.model = T5ForConditionalGeneration.from_pretrained(\n",
    "            model_name_or_path,\n",
    "            attn_implementation=\"flash_attn\",\n",
    "            torch_dtype=torch.bfloat16,\n",
    "        )\n",
    "        engine.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_name_or_path, eos_token=\"</s>\"\n",
    "        )\n",
    "\n",
    "        return engine\n",
    "\n",
    "    def batch_correct(\n",
    "        self,\n",
    "        sentences: List[str],\n",
    "        batch_size: int,\n",
    "        prefix: Optional[str] = \"\",\n",
    "        **generation_params,\n",
    "    ) -> List[List[Any]]:\n",
    "        \"\"\"Correct multiple sentences\"\"\"\n",
    "\n",
    "        if not hasattr(self, \"model\"):\n",
    "            raise RuntimeError(\n",
    "                \"Please load weights using `from_pretrained` method from one of the available models.\"\n",
    "            )\n",
    "        batches = [\n",
    "            sentences[i : i + batch_size] for i in range(0, len(sentences), batch_size)\n",
    "        ]\n",
    "        result = []\n",
    "        pb = tqdm(total=len(batches))\n",
    "        device = self.model.device\n",
    "        for batch in batches:\n",
    "            init_encodings = self.tokenizer.batch_encode_plus(\n",
    "                batch,\n",
    "                max_length=None,\n",
    "                padding=\"longest\",\n",
    "                truncation=False,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            batch_prefix = [prefix + sentence for sentence in batch]\n",
    "            encodings = self.tokenizer.batch_encode_plus(\n",
    "                batch_prefix,\n",
    "                max_length=None,\n",
    "                padding=\"longest\",\n",
    "                truncation=False,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            for k, v in encodings.items():\n",
    "                encodings[k] = v.to(device)\n",
    "            generated_tokens = self.model.generate(\n",
    "                **encodings,\n",
    "                **generation_params,\n",
    "                max_length=init_encodings[\"input_ids\"].shape[1] + 1,\n",
    "            )\n",
    "            ans = self.tokenizer.batch_decode(\n",
    "                generated_tokens, skip_special_tokens=True\n",
    "            )\n",
    "            result.append(ans)\n",
    "            pb.update(1)\n",
    "        return result\n",
    "\n",
    "\n",
    "corrector = T5ModelForSpellingCorruption.from_pretrained(\n",
    "    AvailableCorrectors.ent5_large.value\n",
    ")\n",
    "\n",
    "corrector.model.to(torch.device(\"cuda:3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add support flash attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
